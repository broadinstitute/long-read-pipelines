version 1.0

# utility file for tasks focusing on collecting read length-related metrics

task GetLengthsFromBam {
    meta {
        description:
        "Get read length of reads in a bam (secondary and supplementary alignments are excluded if the BAM is aligned)"
    }
    parameter_meta {
        bam: {localization_optional: true}
    }
    input {
        File bam
    }

    Int disk_sz = 10 + ceil(size(bam, "GiB"))

    String base = basename(bam)
    String local_bam = "/cromwell_root/~{base}"

    command <<<
        set -euxo pipefail

        time gcloud storage cp ~{bam} ~{local_bam}
        samtools view -@1 \
            -F 256 \
            -F 2048 \
            ~{local_bam} \
        | awk -F '\t' '{print length($10)}' \
        > "lengths.txt"
    >>>

    output {
        File read_lengths = "lengths.txt"
    }

    runtime {
        cpu: 2
        memory: "8 GiB"
        disks: "local-disk ~{disk_sz} HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-gcloud-samtools:0.1.1"
    }
}

task GetLengthsFromFastq {
    meta {
        description:
        "Get read length of reads in a FASTQ(.gz) file"
    }
    parameter_meta {
        fastq: {localization_optional: true}
    }
    input {
        File fastq
    }

    Int disk_size = 10 + ceil(size(fastq, "GiB"))

    String base = basename(fastq)
    String local_fq = "/cromwell_root/~{base}"

    command <<<
        set -euxo pipefail

        time gcloud storage cp ~{fastq} ~{local_fq}

        if [[ "~{fastq}" =~ \.gz$ ]];then
            zcat ~{local_fq} | awk '{if(NR%4==2) print length}' > "lengths.txt"
        else
            awk '{if(NR%4==2) print length}' ~{local_fq} > "lengths.txt"
        fi
    >>>

    output {
        File read_lengths = "lengths.txt"
    }

    runtime {
        cpu: 2
        memory: "8 GiB"
        disks: "local-disk ~{disk_size} HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-gcloud-samtools:0.1.1"
    }
}

task GetNumReadsAndShorts {
    meta {
        desciption:
        "Get number of reads and those that are too short. Also compress."
    }
    input {
        File read_lengths_txt
        Int short_threshold
    }

    String prefix = basename(read_lengths_txt, ".txt")
    command <<<
        set -eux

        wc -l ~{read_lengths_txt} | awk '{print $1}' > "total.txt"

        awk -v thesh=~{short_threshold} \
               '{if ($1<thesh) print}' ~{read_lengths_txt} \
            | wc -l \
            | awk '{print $1}' \
        > "shorts.txt"

        mv ~{read_lengths_txt} ~{prefix}.txt
        bzip2 -v9 ~{prefix}.txt
    >>>

    output {
        Float num_seqs = read_float("total.txt")
        Float num_shorts = read_float("shorts.txt")
        File rl_bz2 = "~{prefix}.txt.bz2"
    }
    runtime {cpu: 1 memory: "4 GiB" disks: "local-disk 100 HDD" preemptible_tries: 1 docker: "gcr.io/cloud-marketplace/google/ubuntu2004:latest"}
}

task Dyst {
    meta {
        desciption: "Using a program called dyst to display a txt version of read length histogram"
    }
    input {
        File read_lengths_txt
    }

    command <<<
        set -eux

        mv ~{read_lengths_txt} "read_lengths.txt"
        dyst -h
        dyst -n -b 100 -i "read_lengths.txt" \
            > "read_lengths.hist.txt"
        cat "read_lengths.hist.txt"
    >>>

    output {
        File histogram = "read_lengths.hist.txt"
    }

    runtime {
        cpu: 4
        memory: "20 GiB"
        disks: "local-disk 100 HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-dyst-peaker:0.0.2"
    }
}

task Peaker {
    meta {
        desciption: "Heuristically detect peaks of the txt histogram generated by dyst."
    }
    input {
        File dyst_histogram
    }

    command <<<
        set -eux

        grep -v "^#" ~{dyst_histogram} | awk -F ':' '{print $1}' \
            > "prepped_dyst_plain.hist"

        python3 /opt/find_peaks.py \
            -i "prepped_dyst_plain.hist" \
            -o "peaks.txt"
    >>>

    output {
        Array[Int] peaks = read_lines("peaks.txt")
    }

    runtime {
        disks: "local-disk 100 HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-dyst-peaker:0.0.1"
    }
}

task ReverseYield {
    meta {
        desciption: "Given a read length array, calculate at which lengths does one get [10%, 20%, ..., 90%] of reads, i.e. deciles."
    }
    input {
        File read_lengths_txt
    }

    command <<<
        python3 /opt/reverse_yield.py \
            -i ~{read_lengths_txt} \
            -o "reverse_yield.txt"
    >>>

    output {
        Array[Int] reverse_yield = read_lines("reverse_yield.txt")
    }

    runtime {
        disks: "local-disk 10 HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-dyst-peaker:0.0.2"
    }
}

task Skewness {
    meta {
        desciption: "Measure skewness of the readlength distribution"
    }
    input {
        File read_lengths_txt
    }

    command <<<
        python3 /opt/measure_g1_skew.py \
            -i ~{read_lengths_txt} \
            -o "skew.txt"
    >>>

    output {
        Float skew = read_float("skew.txt")
    }

    runtime {
        disks: "local-disk 10 HDD"
        preemptible_tries:  3
        max_retries:        2
        docker: "us.gcr.io/broad-dsp-lrma/lr-dyst-peaker:0.0.2"
    }
}
